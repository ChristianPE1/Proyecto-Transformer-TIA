# Vision Transformer (ViT) - ImplementaciÃ³n en C++

[![Language](https://img.shields.io/badge/language-C++-blue.svg)](https://isocpp.org/)
[![Standard](https://img.shields.io/badge/C++-17-blue.svg)](https://en.wikipedia.org/wiki/C%2B%2B17)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

Una implementaciÃ³n completa desde cero del **Vision Transformer (ViT)** en C++ puro, capaz de clasificar imÃ¡genes en mÃºltiples datasets mÃ©dicos y tradicionales. Este proyecto implementa el mecanismo de self-attention y arquitectura transformer para visiÃ³n por computadora.

## Tabla de Contenidos

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitectura](#-arquitectura)
- [Datasets Soportados](#-datasets-soportados)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Resultados](#-resultados)
- [DocumentaciÃ³n TÃ©cnica](#-documentaciÃ³n-tÃ©cnica)
- [Contribuir](#-contribuir)
- [Referencias](#-referencias)

## CaracterÃ­sticas

- **ImplementaciÃ³n completa del Vision Transformer** desde cero en C++
- **Multi-Head Self-Attention** con escalado y normalizaciÃ³n
- **Soporte para mÃºltiples datasets**:
  - MNIST clÃ¡sico - Accuracy ~90
  - Fashion-MNIST - Accuracy ~89
  - Afro-MNIST - Accuracy ~85
- **Entrenamiento y evaluaciÃ³n** con mÃ©trica de accuracy
- **Guardado y carga de modelos** entrenados (formato .bin)
- **Procesamiento de patches** de imagen configurable
- **Sin dependencias externas** (implementaciÃ³n pura en C++)

## Arquitectura

### Vision Transformer (ViT)

```
Input Image (28x28) â†’ Patches (7x7) â†’ Linear Projection â†’ 
â†’ Position Embedding â†’ VIT Block â†’ Classification Head
```

**Componentes principales:**

1. **Patch Embedding**: DivisiÃ³n de la imagen en patches y proyecciÃ³n lineal
2. **(VIT Block) Multi-Head Attention**: Mecanismo de atenciÃ³n con mÃºltiples cabezas
3. **(VIT Block) Layer Normalization**: NormalizaciÃ³n de capas para estabilidad
4. **(VIT Block) Feed Forward Network**: Redes completamente conectadas
5. **Classification Head**: Capa final para clasificaciÃ³n

### FÃ³rmula de AtenciÃ³n

```
Attention(Q,K,V) = softmax(QK^T / âˆšd_k)V
```

Donde:
- Q = Query matrix
- K = Key matrix  
- V = Value matrix
- d_k = DimensiÃ³n de las claves

## Datasets Soportados

| Dataset | Clases | TamaÃ±o Entrenamiento | TamaÃ±o Test | DescripciÃ³n |
|---------|--------|---------------------|-------------|-------------|
| **MNIST** | 10 | 60,000 | 10,000 | DÃ­gitos manuscritos |
| **Fashion-MNIST** | 10 | 60,000 | 10,000 | ArtÃ­culos de moda |
| **Afro-MNIST** | 10 | 60,000 | 10,000 | ImÃ¡genes de dÃ­gitos manuscritos africanos |

## InstalaciÃ³n

### Prerrequisitos

- **Compilador C++17** (GCC, Clang, o MSVC)
- **CMake 3.18+**
- **Git** (para clonar el repositorio)

### CompilaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/ChristianPE1/Proyecto-Transformer-TIA.git
cd Proyecto-Transformer-TIA

# Crear directorio de construcciÃ³n
mkdir build && cd build

# Configurar con CMake
cmake ..

# Compilar
make

# O usar CMake para compilar
cmake --build .
```

### Ejecutable generado

```bash
# El ejecutable se genera en build/bin/
./build/bin/main
```

## Uso

### Entrenamiento BÃ¡sico

Cambiar la linea de entrenamiento en `main.cpp` para seleccionar el dataset:

```cpp
// Entrenar con MNIST
ViTMNIST model = train_mnist();

// Entrenar con Fashion-MNIST  
ViTMNIST model = train_fashion();

// Entrenar con OrganCMNIST
ViTMNIST model = train_organc();

// Continuar entrenamiento desde pesos guardados
ViTMNIST model = continue_train_organc();
```

### ConfiguraciÃ³n de ParÃ¡metros

```cpp
int patch_size = 7;              // TamaÃ±o de patches (7x7)
int embed_dim = 64;              // DimensiÃ³n de embedding
int num_heads = 2;               // NÃºmero de cabezas de atenciÃ³n
int num_layers = 3;              // NÃºmero de capas transformer
int mlp_hidden_layers_size = 96; // TamaÃ±o de capas ocultas MLP
int num_classes = 11;            // NÃºmero de clases de salida

ViTMNIST vit_model(patch_size, embed_dim, num_heads, 
                   num_layers, mlp_hidden_layers_size, num_classes);
```

### ParÃ¡metros de Entrenamiento

```cpp
int num_epochs = 15;           // NÃºmero de Ã©pocas
int batch_size = 64;           // TamaÃ±o de lote
float learning_rate = 0.0001f; // Tasa de aprendizaje
int save_each_epoch = 3;       // Guardar cada N Ã©pocas

Trainer trainer(num_epochs, batch_size, learning_rate);
trainer.train(vit_model, train_data, test_data, save_each_epoch);
```

## Estructura del Proyecto

```
Proyecto-Transformer-TIA/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.cpp                    # Punto de entrada principal
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ mnist_loader.hpp        # Cargador de datasets (MNIST, NPY)
â”‚   â”œâ”€â”€ layers/
â”‚   â”‚   â”œâ”€â”€ feed_forward.cpp        # Red feed-forward
â”‚   â”‚   â”œâ”€â”€ layer_norm.cpp          # NormalizaciÃ³n de capas
â”‚   â”‚   â””â”€â”€ linear.cpp              # Capas lineales
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ classification_loss.cpp # FunciÃ³n de pÃ©rdida
â”‚   â”œâ”€â”€ transformer/
â”‚   â”‚   â”œâ”€â”€ attention.cpp           # Multi-head attention
â”‚   â”‚   â””â”€â”€ vit_mnist.cpp          # Vision Transformer principal
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ classifier.cpp          # Clasificador
â”‚       â”œâ”€â”€ matrix.cpp              # Operaciones de matrices
â”‚       â””â”€â”€ trainer.cpp             # Entrenador
â”œâ”€â”€ data/                           # Datasets
â”‚   â”œâ”€â”€ afro/                       # Afro-MNIST (.npy)
â”‚   â”œâ”€â”€ mnist/                      # MNIST clÃ¡sico (.ubyte)
â”‚   â”œâ”€â”€ fashion/                    # Fashion-MNIST (.ubyte)
â”‚   â”œâ”€â”€ organc/                     # OrganCMNIST (.npy)
â”‚   â””â”€â”€ blood/                      # BloodCMNIST (.npy)
â”œâ”€â”€ weights/                        # Modelos entrenados (.bin)
â”œâ”€â”€ CMakeLists.txt                  # ConfiguraciÃ³n de construcciÃ³n
â””â”€â”€ README.md                       # Este archivo
```

## Resultados


| Dataset | Test Accuracy | Ã‰pocas | Batch Size | Learning Rate |
|---------|---------------|--------|------------|---------------|
| MNIST | ~95%* | 10 | 64 | 0.001 |
| Fashion-MNIST | ~80%* | 10 | 64 | 0.001 |
| Afro-MNIST | 61.22% | 15 | 32 | 0.0005 |

*Resultados aproximados, pueden variar segÃºn la configuraciÃ³n y el dataset.

## DocumentaciÃ³n TÃ©cnica

### Mecanismo de AtenciÃ³n

La implementaciÃ³n del **Multi-Head Attention** sigue estos pasos:

1. **ProyecciÃ³n a Q, K, V:**
   ```cpp
   Matrix Q = query.multiply(W_Q);
   Matrix K = key.multiply(W_K);
   Matrix V = value.multiply(W_V);
   ```

2. **CÃ¡lculo de scores (similitud):**
   ```cpp
   float scale = 1.0f / std::sqrt((float)d_model);
   float score = dot_product(Q[i], K[j]) * scale;
   ```

3. **AplicaciÃ³n de Softmax:**
   ```cpp
   attention_weights[i][j] = exp(score - max_score) / sum_exp;
   ```

4. **AplicaciÃ³n de atenciÃ³n a valores:**
   ```cpp
   output[i] = sum(attention_weights[i][j] * V[j]);
   ```

### Carga de Datos

El proyecto soporta dos formatos:

- **MNIST tradicional (.ubyte)**: Formato binario original
- **NPY (.npy)**: Formato NumPy para datasets mÃ©dicos

```cpp
// Cargar MNIST tradicional
MNISTData data = loader.load(images_path, labels_path);

// Cargar formato NPY (OrganCMNIST, BloodCMNIST, Afro-MNIST)
auto [train_data, test_data] = loader.load_organc_mnist(data_dir);
```

### Guardado de Modelos

```cpp
// Guardar pesos del modelo
vit_model.save_weights("vit-{epoch}.bin");
Los pesos se guardan automÃ¡ticamente durante el entrenamiento:

```cpp
// Se guarda como: "vit-{epoch}.bin"
vit_model.save_weights("vit-{epoch}.bin");

// Cargar pesos guardados
vit_model.load_weights("vit-{epoch}.bin");
```

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### Ãreas de mejora

- [ ] ImplementaciÃ³n de data augmentation
- [ ] Soporte para GPU/CUDA
- [ ] OptimizaciÃ³n de memoria
- [ ] MÃ¡s datasets mÃ©dicos
- [ ] Interfaz grÃ¡fica para visualizaciÃ³n

## Referencias

1. **Dosovitskiy, A., et al.** (2020). "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale." *ICLR 2021*. [arXiv:2010.11929](https://arxiv.org/abs/2010.11929)

2. **Vaswani, A., et al.** (2017). "Attention Is All You Need." *NIPS 2017*. [arXiv:1706.03762](https://arxiv.org/abs/1706.03762)

---

## Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## Autor

**Christian PardavÃ© Espinoza** - [ChristianPE1](https://github.com/ChristianPE1)

**Berly Diaz Castro** - [Berly01](https://github.com/Berly01)

**Leonardo Montoya Choque** - [Legonnarth](https://github.com/Legonnarth)

**Saul Condori Machaca** - [SaulCondoriM](https://github.com/SaulCondoriM)

---

*Proyecto desarrollado como parte del curso de TÃ³picos en Inteligencia Artificial (TIA) - UNSA*
